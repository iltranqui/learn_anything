{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segnet Trial\n",
    "<img src='https://ars.els-cdn.com/content/image/1-s2.0-S2452414X20300194-gr3.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # From https://github.com/vinceecws/SegNet_PyTorch\\n    @staticmethod \\n    def save_checkpoint(state, path):\\n        torch.save(state, path)\\n        print(\"Checkpoint saved at {}\".format(path))\\n\\n    @staticmethod\\n    def Train(trainloader, path=None): #epochs is target epoch, path is provided to load saved checkpoint\\n\\n        model = SegNet()\\n        optimizer = optim.SGD(model.parameters(), lr=hyperparam.lr, momentum=hyperparam.momentum)\\n        loss_fn = nn.CrossEntropyLoss()\\n        run_epoch = hyperparam.epochs\\n\\n        if path == None:\\n            epoch = 0\\n            path = os.path.join(os.getcwd(), \\'segnet_weights.pth.tar\\')\\n            print(\"Creating new checkpoint \\'{}\\'\".format(path))\\n        else:\\n            if os.path.isfile(path):\\n                print(\"Loading checkpoint \\'{}\\'\".format(path))\\n                checkpoint = torch.load(path)\\n                epoch = checkpoint[\\'epoch\\']\\n                model.load_state_dict(checkpoint[\\'state_dict\\'])\\n                optimizer.load_state_dict(checkpoint[\\'optimizer\\'])\\n                print(\"Loaded checkpoint \\'{}\\' (epoch {})\".format(path, checkpoint[\\'epoch\\']))\\n            else:\\n                print(\"No checkpoint found at \\'{}\\'\".format(path))\\n                \\n\\n        for i in range(1, run_epoch + 1):\\n            print(\\'Epoch {}:\\'.format(i))\\n            sum_loss = 0.0\\n\\n            for j, data in enumerate(trainloader, 1):\\n                images, labels = data\\n                optimizer.zero_grad()\\n                output = model(images)\\n                loss = loss_fn(output, labels)\\n                loss.backward()\\n                optimizer.step()\\n\\n                sum_loss += loss.item()\\n\\n                print(\\'Loss at {} mini-batch: {}\\'.format(j, loss.item()/trainloader.batch_size))\\n\\n            print(\\'Average loss @ epoch: {}\\'.format((sum_loss/j*trainloader.batch_size)))\\n\\n        print(\"Training complete. Saving checkpoint...\")\\n        Train.save_checkpoint({\\'epoch\\': epoch, \\'state_dict\\': model.state_dict(), \\'optimizer\\' : optimizer.state_dict()}, path)\\n    '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SegNet(nn.Module):\n",
    "    \"\"\"Some Information about MyModule\"\"\"\n",
    "    def __init__(self, in_chn=3, out_chn=32, BN_momentum=0.5):\n",
    "        super(SegNet, self).__init__()\n",
    "\n",
    "        #SegNet Architecture\n",
    "        #Takes input of size in_chn = 3 (RGB images have 3 channels)\n",
    "        #Outputs size label_chn (N # of classes)\n",
    "\n",
    "        #ENCODING consists of 5 stages\n",
    "        #Stage 1, 2 has 2 layers of Convolution + Batch Normalization + Max Pool respectively\n",
    "        #Stage 3, 4, 5 has 3 layers of Convolution + Batch Normalization + Max Pool respectively\n",
    "\n",
    "        #General Max Pool 2D for ENCODING layers\n",
    "        #Pooling indices are stored for Upsampling in DECODING layers+\n",
    "\n",
    "        # BN_momentum  is for the batchNormalization to reduce overfitting and outliers\n",
    "\n",
    "        self.in_chn = in_chn  # Input: N*N*3\n",
    "        self.out_chn = out_chn \n",
    "\n",
    "        self.MaxEn = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)              # Output: N/2*N/2*3\n",
    "        self.ConvEn11 = nn.Conv2d(in_chn, 64, kernel_size=3, padding=1),                    # O: N/2*N/2*64                 \n",
    "        self.BNEn11 = nn.Sequential(\n",
    "                        nn.BatchNorm2d(64, momentum=BN_momentum),                   # O: N/2*2/N*64 \n",
    "                        nn.ReLU()\n",
    "        )\n",
    "        self.ConvEn12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)              # O: N/2*N/2*64\n",
    "        self.BNEn12 = nn.BatchNorm2d(64, momentum=BN_momentum)                   # O: N/2*N/2*64\n",
    "\n",
    "        # here there is the MAxPooling layer, it is added later ->               # O: N/4*N/4*64\n",
    "\n",
    "        self.ConvEn21 = nn.Conv2d(64, 128, kernel_size=3, padding=1)             # O: N/4*N/4*128\n",
    "        self.BNEn21 = nn.BatchNorm2d(128, momentum=BN_momentum)                  # O: N/4*N/4*128\n",
    "        self.ConvEn22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)            # O: N/4*N/4*128\n",
    "        self.BNEn22 = nn.BatchNorm2d(128, momentum=BN_momentum)                  # O: N/4*N/4*128\n",
    "\n",
    "                                                                                 #  O: N/8*N/*256\n",
    "                                                                                 #  \n",
    "        self.ConvEn31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)            #  O: N/8*N/*256\n",
    "        self.BNEn31 = nn.BatchNorm2d(256, momentum=BN_momentum)                  #  O: N/8*N/*256\n",
    "        self.ConvEn32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)            #  O: N/8*N/*256\n",
    "        self.BNEn32 = nn.BatchNorm2d(256, momentum=BN_momentum)                  #  O: N/8*N/*256\n",
    "        self.ConvEn33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)            #  O: N/8*N/*256\n",
    "        self.BNEn33 = nn.BatchNorm2d(256, momentum=BN_momentum)                  #  O: N/8*N/*256\n",
    "\n",
    "                                                                                 #  MaxPooling: N/16*N/16*256\n",
    "\n",
    "        self.ConvEn41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)            #  O: N/16*N/*512\n",
    "        self.BNEn41 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvEn42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)            #  O: N/16*N/*512\n",
    "        self.BNEn42 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvEn43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)            #  O: N/16*N/*512\n",
    "        self.BNEn43 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "\n",
    "                                                                                 #  MaxPooling: N/32*N/32*512\n",
    "\n",
    "        self.ConvEn51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)            #  O: N/32*N/32*512\n",
    "        self.BNEn51 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvEn52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)            #  O: N/32*N/32*512\n",
    "        self.BNEn52 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvEn53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)            #  O: N/32*N/32*512\n",
    "        self.BNEn53 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "\n",
    "\n",
    "        #DECODING consists of 5 stages\n",
    "        #Each stage corresponds to their respective counterparts in ENCODING\n",
    "\n",
    "        #General Max Pool 2D/Upsampling for DECODING layers\n",
    "        self.MaxDe = nn.MaxUnpool2d(2, stride=2) \n",
    "\n",
    "        self.ConvDe53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)  #  O: N/32*N/32*512\n",
    "        self.BNDe53 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvDe52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)  #  O: N/32*N/32*512\n",
    "        self.BNDe52 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvDe51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)  #  O: N/32*N/32*512\n",
    "        self.BNDe51 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvDe43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)  #  O: N/16*N/*512\n",
    "        self.BNDe43 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvDe42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)  #  O: N/16*N/*512\n",
    "        self.BNDe42 = nn.BatchNorm2d(512, momentum=BN_momentum)\n",
    "        self.ConvDe41 = nn.Conv2d(512, 256, kernel_size=3, padding=1)  #  O: N/16*N/*256\n",
    "        self.BNDe41 = nn.BatchNorm2d(256, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvDe33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)  #  O: N/8*N/*256\n",
    "        self.BNDe33 = nn.BatchNorm2d(256, momentum=BN_momentum)\n",
    "        self.ConvDe32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)  #  O: N/8*N/*256\n",
    "        self.BNDe32 = nn.BatchNorm2d(256, momentum=BN_momentum)\n",
    "        self.ConvDe31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)  #  O: N/8*N/*128\n",
    "        self.BNDe31 = nn.BatchNorm2d(128, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvDe22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)  #  O: N/4*N/4*128\n",
    "        self.BNDe22 = nn.BatchNorm2d(128, momentum=BN_momentum)\n",
    "        self.ConvDe21 = nn.Conv2d(128, 64, kernel_size=3, padding=1)  #  O: N/4*N/4*64\n",
    "        self.BNDe21 = nn.BatchNorm2d(64, momentum=BN_momentum)\n",
    "\n",
    "        self.ConvDe12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)  #  O: N/2*N/2*64\n",
    "        self.BNDe12 = nn.BatchNorm2d(64, momentum=BN_momentum)\n",
    "        self.ConvDe11 = nn.Conv2d(64, self.out_chn, kernel_size=3, padding=1)  #  O: N/2*N/2*self.out_chn\n",
    "        self.BNDe11 = nn.BatchNorm2d(self.out_chn, momentum=BN_momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "                #ENCODE LAYERS\n",
    "                \n",
    "        #Stage 1\n",
    "        x = self.BNEn11(self.ConvEn11(x))\n",
    "        print(type(x))\n",
    "        x = nn.ReLU(self.BNEn12(self.ConvEn12(x))) \n",
    "        x, ind1 = self.MaxEn(x)\n",
    "        size1 = x.size()\n",
    "\n",
    "        #Stage 2\n",
    "        x = nn.ReLU(self.BNEn21(self.ConvEn21(x))) \n",
    "        x = nn.ReLU(self.BNEn22(self.ConvEn22(x))) \n",
    "        x, ind2 = self.MaxEn(x)\n",
    "        size2 = x.size()\n",
    "\n",
    "        #Stage 3\n",
    "        x = nn.ReLU(self.BNEn31(self.ConvEn31(x))) \n",
    "        x = nn.ReLU(self.BNEn32(self.ConvEn32(x))) \n",
    "        x = nn.ReLU(self.BNEn33(self.ConvEn33(x)))   \n",
    "        x, ind3 = self.MaxEn(x)\n",
    "        size3 = x.size()\n",
    "\n",
    "        #Stage 4\n",
    "        x = nn.ReLU(self.BNEn41(self.ConvEn41(x))) \n",
    "        x = nn.ReLU(self.BNEn42(self.ConvEn42(x))) \n",
    "        x = nn.ReLU(self.BNEn43(self.ConvEn43(x)))   \n",
    "        x, ind4 = self.MaxEn(x)\n",
    "        size4 = x.size()\n",
    "\n",
    "        #Stage 5\n",
    "        x = nn.ReLU(self.BNEn51(self.ConvEn51(x))) \n",
    "        x = nn.ReLU(self.BNEn52(self.ConvEn52(x))) \n",
    "        x = nn.ReLU(self.BNEn53(self.ConvEn53(x)))   \n",
    "        x, ind5 = self.MaxEn(x)\n",
    "        size5 = x.size()\n",
    "\n",
    "        #DECODE LAYERS\n",
    "        #Stage 5\n",
    "        x = self.MaxDe(x, ind5, output_size=size4)\n",
    "        x = nn.ReLU(self.BNDe53(self.ConvDe53(x)))\n",
    "        x = nn.ReLU(self.BNDe52(self.ConvDe52(x)))\n",
    "        x = nn.ReLU(self.BNDe51(self.ConvDe51(x)))\n",
    "\n",
    "        #Stage 4\n",
    "        x = self.MaxDe(x, ind4, output_size=size3)\n",
    "        x = nn.ReLU(self.BNDe43(self.ConvDe43(x)))\n",
    "        x = nn.ReLU(self.BNDe42(self.ConvDe42(x)))\n",
    "        x = nn.ReLU(self.BNDe41(self.ConvDe41(x)))\n",
    "\n",
    "        #Stage 3\n",
    "        x = self.MaxDe(x, ind3, output_size=size2)\n",
    "        x = nn.ReLU(self.BNDe33(self.ConvDe33(x)))\n",
    "        x = nn.ReLU(self.BNDe32(self.ConvDe32(x)))\n",
    "        x = nn.ReLU(self.BNDe31(self.ConvDe31(x)))\n",
    "\n",
    "        #Stage 2\n",
    "        x = self.MaxDe(x, ind2, output_size=size1)\n",
    "        x = nn.ReLU(self.BNDe22(self.ConvDe22(x)))\n",
    "        x = nn.ReLU(self.BNDe21(self.ConvDe21(x)))\n",
    "\n",
    "        #Stage 1\n",
    "        x = self.MaxDe(x, ind1)\n",
    "        x = nn.ReLU(self.BNDe12(self.ConvDe12(x)))\n",
    "        x = self.ConvDe11(x)\n",
    "\n",
    "        x = nn.Softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\"\"\"\n",
    "    # From https://github.com/vinceecws/SegNet_PyTorch\n",
    "    @staticmethod \n",
    "    def save_checkpoint(state, path):\n",
    "        torch.save(state, path)\n",
    "        print(\"Checkpoint saved at {}\".format(path))\n",
    "\n",
    "    @staticmethod\n",
    "    def Train(trainloader, path=None): #epochs is target epoch, path is provided to load saved checkpoint\n",
    "\n",
    "        model = SegNet()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=hyperparam.lr, momentum=hyperparam.momentum)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        run_epoch = hyperparam.epochs\n",
    "\n",
    "        if path == None:\n",
    "            epoch = 0\n",
    "            path = os.path.join(os.getcwd(), 'segnet_weights.pth.tar')\n",
    "            print(\"Creating new checkpoint '{}'\".format(path))\n",
    "        else:\n",
    "            if os.path.isfile(path):\n",
    "                print(\"Loading checkpoint '{}'\".format(path))\n",
    "                checkpoint = torch.load(path)\n",
    "                epoch = checkpoint['epoch']\n",
    "                model.load_state_dict(checkpoint['state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                print(\"Loaded checkpoint '{}' (epoch {})\".format(path, checkpoint['epoch']))\n",
    "            else:\n",
    "                print(\"No checkpoint found at '{}'\".format(path))\n",
    "                \n",
    "\n",
    "        for i in range(1, run_epoch + 1):\n",
    "            print('Epoch {}:'.format(i))\n",
    "            sum_loss = 0.0\n",
    "\n",
    "            for j, data in enumerate(trainloader, 1):\n",
    "                images, labels = data\n",
    "                optimizer.zero_grad()\n",
    "                output = model(images)\n",
    "                loss = loss_fn(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                sum_loss += loss.item()\n",
    "\n",
    "                print('Loss at {} mini-batch: {}'.format(j, loss.item()/trainloader.batch_size))\n",
    "\n",
    "            print('Average loss @ epoch: {}'.format((sum_loss/j*trainloader.batch_size)))\n",
    "\n",
    "        print(\"Training complete. Saving checkpoint...\")\n",
    "        Train.save_checkpoint({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer' : optimizer.state_dict()}, path)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegNet(\n",
       "  (MaxEn): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (BNEn11): Sequential(\n",
       "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (ConvEn12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn12): BatchNorm2d(64, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn21): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn21): BatchNorm2d(128, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn22): BatchNorm2d(128, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn31): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn31): BatchNorm2d(256, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn32): BatchNorm2d(256, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn33): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn33): BatchNorm2d(256, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn41): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn41): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn42): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn43): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn51): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn52): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn52): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvEn53): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNEn53): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (MaxDe): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  (ConvDe53): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe53): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe52): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe52): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe51): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe43): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe42): BatchNorm2d(512, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe41): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe41): BatchNorm2d(256, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe33): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe33): BatchNorm2d(256, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe32): BatchNorm2d(256, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe31): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe31): BatchNorm2d(128, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe22): BatchNorm2d(128, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe21): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe21): BatchNorm2d(64, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe12): BatchNorm2d(64, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (ConvDe11): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BNDe11): BatchNorm2d(32, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # print Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model(x)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m) \u001b[38;5;66;03m# -> it is tensor\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SegNet()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.virtualenvs/ml_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/ml_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 107\u001b[0m, in \u001b[0;36mSegNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;66;03m#ENCODE LAYERS\u001b[39;00m\n\u001b[1;32m    105\u001b[0m             \n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m#Stage 1\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBNEn11(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConvEn11\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(x))\n\u001b[1;32m    109\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBNEn12(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mConvEn12(x))) \n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    x = torch.rand(1,3,224,224) # -> it is tensor\n",
    "    model = SegNet()\n",
    "    print(model(x).shape)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-debugger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
