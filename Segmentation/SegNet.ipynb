{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segnet Trial for Inference\n",
    "<img src='https://ars.els-cdn.com/content/image/1-s2.0-S2452414X20300194-gr3.jpg' heigth=600 width=800>\n",
    "\n",
    "The following model is ready for inference and only that ! It has not been trained so the outputs are completly random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # From https://github.com/vinceecws/SegNet_PyTorch\\n    @staticmethod \\n    def save_checkpoint(state, path):\\n        torch.save(state, path)\\n        print(\"Checkpoint saved at {}\".format(path))\\n\\n    @staticmethod\\n    def Train(trainloader, path=None): #epochs is target epoch, path is provided to load saved checkpoint\\n\\n        model = SegNet()\\n        optimizer = optim.SGD(model.parameters(), lr=hyperparam.lr, momentum=hyperparam.momentum)\\n        loss_fn = nn.CrossEntropyLoss()\\n        run_epoch = hyperparam.epochs\\n\\n        if path == None:\\n            epoch = 0\\n            path = os.path.join(os.getcwd(), \\'segnet_weights.pth.tar\\')\\n            print(\"Creating new checkpoint \\'{}\\'\".format(path))\\n        else:\\n            if os.path.isfile(path):\\n                print(\"Loading checkpoint \\'{}\\'\".format(path))\\n                checkpoint = torch.load(path)\\n                epoch = checkpoint[\\'epoch\\']\\n                model.load_state_dict(checkpoint[\\'state_dict\\'])\\n                optimizer.load_state_dict(checkpoint[\\'optimizer\\'])\\n                print(\"Loaded checkpoint \\'{}\\' (epoch {})\".format(path, checkpoint[\\'epoch\\']))\\n            else:\\n                print(\"No checkpoint found at \\'{}\\'\".format(path))\\n                \\n\\n        for i in range(1, run_epoch + 1):\\n            print(\\'Epoch {}:\\'.format(i))\\n            sum_loss = 0.0\\n\\n            for j, data in enumerate(trainloader, 1):\\n                images, labels = data\\n                optimizer.zero_grad()\\n                output = model(images)\\n                loss = loss_fn(output, labels)\\n                loss.backward()\\n                optimizer.step()\\n\\n                sum_loss += loss.item()\\n\\n                print(\\'Loss at {} mini-batch: {}\\'.format(j, loss.item()/trainloader.batch_size))\\n\\n            print(\\'Average loss @ epoch: {}\\'.format((sum_loss/j*trainloader.batch_size)))\\n\\n        print(\"Training complete. Saving checkpoint...\")\\n        Train.save_checkpoint({\\'epoch\\': epoch, \\'state_dict\\': model.state_dict(), \\'optimizer\\' : optimizer.state_dict()}, path)\\n    '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SegNet(nn.Module):\n",
    "    def __init__(self, classes=10):\n",
    "        super(SegNet, self).__init__()\n",
    "\n",
    "        batchNorm_momentum = 0.1\n",
    "\n",
    "        self.conv11 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn11 = nn.BatchNorm2d(64, momentum=batchNorm_momentum)\n",
    "        self.conv12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn12 = nn.BatchNorm2d(64, momentum=batchNorm_momentum)\n",
    "\n",
    "        self.conv21 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn21 = nn.BatchNorm2d(128, momentum=batchNorm_momentum)\n",
    "        self.conv22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn22 = nn.BatchNorm2d(128, momentum=batchNorm_momentum)\n",
    "\n",
    "        self.conv31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn31 = nn.BatchNorm2d(256, momentum=batchNorm_momentum)\n",
    "        self.conv32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn32 = nn.BatchNorm2d(256, momentum=batchNorm_momentum)\n",
    "        self.conv33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn33 = nn.BatchNorm2d(256, momentum=batchNorm_momentum)\n",
    "\n",
    "        self.conv41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn41 = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "        self.conv42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn42 = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "        self.conv43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn43 = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "\n",
    "        self.conv51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn51 = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "        self.conv52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn52 = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "        self.conv53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn53 = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "\n",
    "        self.conv53d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn53d = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "        self.conv52d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn52d = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "        self.conv51d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn51d = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "\n",
    "        self.conv43d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn43d = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "        self.conv42d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn42d = nn.BatchNorm2d(512, momentum=batchNorm_momentum)\n",
    "        self.conv41d = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.bn41d = nn.BatchNorm2d(256, momentum=batchNorm_momentum)\n",
    "\n",
    "        self.conv33d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn33d = nn.BatchNorm2d(256, momentum=batchNorm_momentum)\n",
    "        self.conv32d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn32d = nn.BatchNorm2d(256, momentum=batchNorm_momentum)\n",
    "        self.conv31d = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.bn31d = nn.BatchNorm2d(128, momentum=batchNorm_momentum)\n",
    "\n",
    "        self.conv22d = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn22d = nn.BatchNorm2d(128, momentum=batchNorm_momentum)\n",
    "        self.conv21d = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.bn21d = nn.BatchNorm2d(64, momentum=batchNorm_momentum)\n",
    "\n",
    "        self.conv12d = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn12d = nn.BatchNorm2d(64, momentum=batchNorm_momentum)\n",
    "        self.conv11d = nn.Conv2d(64, classes, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Stage 1\n",
    "        x11 = F.relu(self.bn11(self.conv11(x)))\n",
    "        x12 = F.relu(self.bn12(self.conv12(x11)))\n",
    "        x1_size = x12.size()\n",
    "        x1p, id1 = F.max_pool2d(x12, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Stage 2\n",
    "        x21 = F.relu(self.bn21(self.conv21(x1p)))\n",
    "        x22 = F.relu(self.bn22(self.conv22(x21)))\n",
    "        x2_size = x22.size()\n",
    "        x2p, id2 = F.max_pool2d(x22, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Stage 3\n",
    "        x31 = F.relu(self.bn31(self.conv31(x2p)))\n",
    "        x32 = F.relu(self.bn32(self.conv32(x31)))\n",
    "        x33 = F.relu(self.bn33(self.conv33(x32)))\n",
    "        x3_size = x33.size()\n",
    "        x3p, id3 = F.max_pool2d(x33, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Stage 4\n",
    "        x41 = F.relu(self.bn41(self.conv41(x3p)))\n",
    "        x42 = F.relu(self.bn42(self.conv42(x41)))\n",
    "        x43 = F.relu(self.bn43(self.conv43(x42)))\n",
    "        x4_size = x43.size()\n",
    "        x4p, id4 = F.max_pool2d(x43, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Stage 5\n",
    "        x51 = F.relu(self.bn51(self.conv51(x4p)))\n",
    "        x52 = F.relu(self.bn52(self.conv52(x51)))\n",
    "        x53 = F.relu(self.bn53(self.conv53(x52)))\n",
    "        x5_size = x53.size()\n",
    "        x5p, id5 = F.max_pool2d(x53, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Stage 5d\n",
    "        x5d = F.max_unpool2d(x5p, id5, kernel_size=2, stride=2, output_size=x5_size)\n",
    "        x53d = F.relu(self.bn53d(self.conv53d(x5d)))\n",
    "        x52d = F.relu(self.bn52d(self.conv52d(x53d)))\n",
    "        x51d = F.relu(self.bn51d(self.conv51d(x52d)))\n",
    "\n",
    "        # Stage 4d\n",
    "        x4d = F.max_unpool2d(x51d, id4, kernel_size=2, stride=2, output_size=x4_size)\n",
    "        x43d = F.relu(self.bn43d(self.conv43d(x4d)))\n",
    "        x42d = F.relu(self.bn42d(self.conv42d(x43d)))\n",
    "        x41d = F.relu(self.bn41d(self.conv41d(x42d)))\n",
    "\n",
    "        # Stage 3d\n",
    "        x3d = F.max_unpool2d(x41d, id3, kernel_size=2, stride=2, output_size=x3_size)\n",
    "        x33d = F.relu(self.bn33d(self.conv33d(x3d)))\n",
    "        x32d = F.relu(self.bn32d(self.conv32d(x33d)))\n",
    "        x31d = F.relu(self.bn31d(self.conv31d(x32d)))\n",
    "\n",
    "        # Stage 2d\n",
    "        x2d = F.max_unpool2d(x31d, id2, kernel_size=2, stride=2, output_size=x2_size)\n",
    "        x22d = F.relu(self.bn22d(self.conv22d(x2d)))\n",
    "        x21d = F.relu(self.bn21d(self.conv21d(x22d)))\n",
    "\n",
    "        # Stage 1d\n",
    "        x1d = F.max_unpool2d(x21d, id1, kernel_size=2, stride=2, output_size=x1_size)\n",
    "        x12d = F.relu(self.bn12d(self.conv12d(x1d)))\n",
    "        x11d = self.conv11d(x12d)\n",
    "\n",
    "        #x11d = torch.nn.functional.softmax(x11d,dim=1)\n",
    "        #x11d = torch.argmax(x11d, dim=1,keepdim=True)    # functioin deestroys the gradients, so the loss cannot be computed ! \n",
    "\n",
    "        \"\"\"_summary_\n",
    "        This error is raised if the model output or loss has been detached from the computation graph e.g. via:\n",
    "\n",
    "        using another library such as numpy\n",
    "        using non-differentiable operations such as torch.argmax\n",
    "        explicitly detaching the tensor via tensor = tensor.detach()\n",
    "        rewrapping the tensor via x = torch.tensor(x)\n",
    "        or if the gradient calculation was disabled in the current context or globally such that no computation graph was created at all.\n",
    "        \"\"\"\n",
    "\n",
    "        return x11d\n",
    "    \n",
    "    # Holy shit and mother mamma mia ! Quanto adesso sto bestemmiando !!! \n",
    "    def postprocessing(self, x, classes=10):\n",
    "        \"\"\"\n",
    "        The raw SegNet outputs a final tensor of [batch,classes,height,width] of elements where [k,0,0] is a value to determine the probability that the pixel in [0,0] belongs to class K \n",
    "        1st: use the Softmak function to transform all elements along dim=1 so that along [batch,k,:,:] all the elements are probability with sum 1\n",
    "        2nd: argmax function return the K class to which the softmax function provides a better chance to be, thus obtaining\n",
    "        \n",
    "        Output: a [batch,1,height,width] Mask with values from (0,classes)\n",
    "        \"\"\"\n",
    "\n",
    "        x = torch.nn.functional.softmax(x,dim=1)\n",
    "        x = torch.argmax(x, dim=1,keepdim=True)\n",
    "        return x.to(torch.float32)\n",
    "        \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    # From https://github.com/vinceecws/SegNet_PyTorch\n",
    "    @staticmethod \n",
    "    def save_checkpoint(state, path):\n",
    "        torch.save(state, path)\n",
    "        print(\"Checkpoint saved at {}\".format(path))\n",
    "\n",
    "    @staticmethod\n",
    "    def Train(trainloader, path=None): #epochs is target epoch, path is provided to load saved checkpoint\n",
    "\n",
    "        model = SegNet()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=hyperparam.lr, momentum=hyperparam.momentum)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        run_epoch = hyperparam.epochs\n",
    "\n",
    "        if path == None:\n",
    "            epoch = 0\n",
    "            path = os.path.join(os.getcwd(), 'segnet_weights.pth.tar')\n",
    "            print(\"Creating new checkpoint '{}'\".format(path))\n",
    "        else:\n",
    "            if os.path.isfile(path):\n",
    "                print(\"Loading checkpoint '{}'\".format(path))\n",
    "                checkpoint = torch.load(path)\n",
    "                epoch = checkpoint['epoch']\n",
    "                model.load_state_dict(checkpoint['state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                print(\"Loaded checkpoint '{}' (epoch {})\".format(path, checkpoint['epoch']))\n",
    "            else:\n",
    "                print(\"No checkpoint found at '{}'\".format(path))\n",
    "                \n",
    "\n",
    "        for i in range(1, run_epoch + 1):\n",
    "            print('Epoch {}:'.format(i))\n",
    "            sum_loss = 0.0\n",
    "\n",
    "            for j, data in enumerate(trainloader, 1):\n",
    "                images, labels = data\n",
    "                optimizer.zero_grad()\n",
    "                output = model(images)\n",
    "                loss = loss_fn(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                sum_loss += loss.item()\n",
    "\n",
    "                print('Loss at {} mini-batch: {}'.format(j, loss.item()/trainloader.batch_size))\n",
    "\n",
    "            print('Average loss @ epoch: {}'.format((sum_loss/j*trainloader.batch_size)))\n",
    "\n",
    "        print(\"Training complete. Saving checkpoint...\")\n",
    "        Train.save_checkpoint({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer' : optimizer.state_dict()}, path)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegNet(\n",
       "  (conv11): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv21): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv31): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv32): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv33): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn33): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv41): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv51): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv52): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn52): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv53): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn53): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv53d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn53d): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv52d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn52d): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv51d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn51d): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv43d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn43d): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv42d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn42d): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv41d): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn41d): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv33d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn33d): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv32d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn32d): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv31d): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn31d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv22d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn22d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv21d): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn21d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn12d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11d): Conv2d(64, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # print Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    x = torch.rand(1,3,224,224) # -> it is tensor\n",
    "    model = SegNet()\n",
    "    print(model(x).shape)\n",
    "    print(f\"Output: 1 channel for every single class\\n{model(x).shape}\")\n",
    "    print(f\"POSTPROCESSING: {model.postprocessing(model(x)).shape} \\n TYPE:{model.postprocessing(model(x)).dtype}\")\n",
    "    print(f\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Softmax Classification: The softmax function is applied to the output of the final layer in the decoder. This transforms the decoder’s output into a set of values between 0 and 1, which can be interpreted as probabilities. The sum of these values for each pixel will be 1.\n",
    "* K-Channel Image: The output is a K-channel image, where each channel corresponds to one of the K classes. For each pixel, the value in a channel represents the probability that the pixel belongs to the corresponding class.\n",
    "* Pixel-wise Maximum Probability: The predicted segmentation is obtained by assigning each pixel to the class with the maximum probability at that pixel. In other words, for each pixel, we look at the K probabilities in the K channels, and the class corresponding to the highest probability is chosen as the prediction for that pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 224, 224])\n",
      "Output: 1 channel for every single class\n",
      "torch.Size([1, 10, 224, 224])\n",
      "POSTPROCESSING: torch.Size([1, 1, 224, 224, 10]) \n",
      " TYPE:torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SegNet e il modello della Rete\n",
    "\n",
    "Allora finora i mask che pensavo sono [1,height,width] con fomrati int8 e ogni pixel ha un suo label. Finora tutto bene, ma quando provi a fare la segmentation che ti ritorivi con l’output si di UNet sia d iSegNet che sono [1,k,heihgt,width] pensi che potresti fare una inferenza con una argmaxz, ma l’argmax non tiene i gradienti. \n",
    "\n",
    "Per cui non esiste una approssimazione attorno a questa cosa ma l’approccio in generale è quello di creare il dataset da 0, con maschere binarie, una per ogni fottura classe alla fine, va che bello ! Almeno il percorso in avanti l’ho trovato diciamo. XD\n",
    "\n",
    "So now we are writing the script in order to have n binary masks for the number of classes, and combine that in the freaking output ! Oh my freaking model, damn it ! This is why you need to become one with the data and one with the model before hand ! This is freaking an adventure honestly, and one woerth pursuing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-debugger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
