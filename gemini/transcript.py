# importing the module
from youtube_transcript_api import YouTubeTranscriptApi

# retrieve the available transcripts
transcript_list = YouTubeTranscriptApi.list_transcripts('c3b-JASoPi0')

# iterate over all available transcripts
for transcript in transcript_list:

    # the Transcript object provides metadata
    # properties
    print(
        transcript.video_id,
        transcript.language,
        transcript.language_code,
    
        # whether it has been manually created or
        # generated by YouTube
        transcript.is_generated,
        
        # whether this transcript can be translated
        # or not
        transcript.is_translatable,
        
        # a list of languages the transcript can be
        # translated to
        transcript.translation_languages,
    )

    # fetch the actual transcript data
    print(transcript.fetch())

    # translating the transcript will return another
    # transcript object
    print(transcript.translate('en').fetch())

# you can also directly filter for the language you are
# looking for, using the transcript list
try:
    transcript = transcript_list.find_transcript(['en'])
except Exception as e:
    print("Error finding transcript:", e)

# or just filter for manually created transcripts
try:
    transcript = transcript_list.find_manually_created_transcript(['en'])
except Exception as e:
    print("Error finding manually created transcript:", e)

# importing modules
from youtube_transcript_api import YouTubeTranscriptApi

# using the srt variable with the list of dictionaries
# obtained by the .get_transcript() function
srt = YouTubeTranscriptApi.get_transcript("c3b-JASoPi0")

# creating or overwriting a file "subtitles.txt" with
# the info inside the context manager
with open("subtitles.txt", "w") as f:

        # iterating through each element of list srt
    for i in srt:
        # writing each element of srt on a new line
        f.write("{}\n".format(i))

## 
import ast

def extract_text_from_subtitles(input_file, output_file):
    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:
        for line in infile:
            # Convert the string representation of the dictionary to an actual dictionary
            subtitle_dict = ast.literal_eval(line.strip())
            # Extract the text value
            text = subtitle_dict.get('text', '')
            # Write the text to the output file
            outfile.write(text + '\n')

# Specify the input and output file names
input_file = 'subtitles.txt'
output_file = 'text_only.txt'

# Call the function to extract text
extract_text_from_subtitles(input_file, output_file)

"""
Install the Google AI Python SDK

$ pip install google-generativeai
"""

import os
import google.generativeai as genai
from dotenv import load_dotenv
import os

# Load environment variables from .env file
load_dotenv()

# Access the API key
api_key = os.getenv("GEMINI_API_KEY")

genai.configure(api_key=api_key)

# Create the model
generation_config = {
  "temperature": 1,
  "top_p": 0.95,
  "top_k": 64,
  "max_output_tokens": 8192*8,
  "response_mime_type": "text/plain",
}

model = genai.GenerativeModel(
  model_name="gemini-1.5-flash",
  generation_config=generation_config,
  # safety_settings = Adjust safety settings
  # See https://ai.google.dev/gemini-api/docs/safety-settings
)

chat_session = model.start_chat(
  history=[
  ]
)

# Read the contents of the text_only.txt file
with open('text_only.txt', 'r') as file:
    contents = file.read()

Instructions = 'Generate a numbered list of 10 points to summarize following text and provide a detailed explanation for each point.\n\n'

# Send the contents as input to the chat session
response = chat_session.send_message(Instructions + contents)

print(response.text)

# Save the summary to a text file
with open('summary.txt', 'w') as file:
    file.write(response.text)